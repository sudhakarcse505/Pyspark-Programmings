{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21c0059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Window-functions').master('local[1]').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e098256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- superior_emp_id: long (nullable = true)\n",
      " |-- year_joined: string (nullable = true)\n",
      " |-- emp_dept_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |\n",
      "|8     |SmithV  |-1             |2018       |10         |M     |3000  |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp = [(1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000),(8,\"SmithV\",-1,\"2018\",\"10\",\"M\",3000), \\\n",
    "    (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000), \\\n",
    "    (3,\"Williams\",1,\"2010\",\"10\",\"M\",1000), \\\n",
    "    (4,\"Jones\",2,\"2005\",\"10\",\"F\",2000), \\\n",
    "    (5,\"Brown\",2,\"2010\",\"40\",\"\",-1), \\\n",
    "      (6,\"Brown\",2,\"2010\",\"50\",\"\",-1) \\\n",
    "  ]\n",
    "\n",
    "empColumns = [\"emp_id\",\"name\",\"superior_emp_id\",\"year_joined\",\"emp_dept_id\",\"gender\",\"salary\"]\n",
    "\n",
    "empDF = spark.createDataFrame(data=emp, schema = empColumns)\n",
    "empDF.printSchema()\n",
    "empDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f6bbd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|        | employee|       true|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.createOrReplaceTempView(\"employee\")\n",
    "spark.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c57977a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from employee').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "579aa4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Want to get the result salary in desc order for every department'''\n",
    "\n",
    "q = ' select * from employee order by emp_dept_id asc, salary desc'\n",
    "\n",
    "spark.sql(q).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Window Ranking Functions'''\n",
    "\n",
    "1.Row_Number() - will give you sequence of row_numbers in each group \n",
    "\n",
    "2.Rank() - will give you seq of ranks in each group but can skip ranks if finds any duplicate values\n",
    "\n",
    "3.Dense_Rank() - will give you seq of ranks in each group but can't skip ranks if finds any duplicate values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67b17967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|rnk|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---+\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|  1|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|  1|\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  1|\n",
      "|     8|  SmithV|             -1|       2018|         10|     M|  3000|  2|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  3|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  4|\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|  1|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = 'select *,row_number() over(partition by emp_dept_id order by salary desc) as rnk from employee'\n",
    "\n",
    "spark.sql(q).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebd35a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|rnk|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---+\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|  1|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|  1|\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  1|\n",
      "|     8|  SmithV|             -1|       2018|         10|     M|  3000|  1|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  3|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  4|\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|  1|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q1 = 'select *,rank() over(partition by emp_dept_id order by salary desc) as rnk from employee'\n",
    "\n",
    "spark.sql(q1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2d1add6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|rnk|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---+\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|  1|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|  1|\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  1|\n",
      "|     8|  SmithV|             -1|       2018|         10|     M|  3000|  1|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  2|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  3|\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|  1|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q2 = 'select *,dense_rank() over(partition by emp_dept_id order by salary desc) as rnk from employee'\n",
    "\n",
    "spark.sql(q2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ef21b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------------+-----------+-----------+------+------+---+\n",
      "|emp_id| name|superior_emp_id|year_joined|emp_dept_id|gender|salary|rnk|\n",
      "+------+-----+---------------+-----------+-----------+------+------+---+\n",
      "|     4|Jones|              2|       2005|         10|     F|  2000|  2|\n",
      "+------+-----+---------------+-----------+-----------+------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''get the second highest salary in each department'''\n",
    "\n",
    "q3 = '''select * from (select *,dense_rank() over(partition by emp_dept_id order by salary desc) as rnk from employee) a \n",
    "      where rnk=2'''\n",
    "\n",
    "spark.sql(q3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f196bfdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
